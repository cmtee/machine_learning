---
title: "ML_PS1"
author: "Clarice Tee"
date: January 21, 2025
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
# Part 1

```{python}
picture =r'C:\Users\clari\OneDrive\Documents\Machine Learning\ps1'
```

1.a. ![Bias-Variance](bias-variance.png) 


1.b. squared bias-this goes down monotonically until it flattens out because greater flexibility leads to the model better being able to capture the true relationship in the data, until a certain point (diminishing returns) where it doesn't add much else.

irreducible error- this is the lower limit of the test MSE, thus it is a straight line. The test MSE is above tis line and the part of the training MSE below this line is when the data has been overfitted.

test MSE- its shape is concave, with the curve going upwards because more flexibility yields a better fit, until it overfits.

training MSE-  this error goes down monotonically since more flexibility leads to better fitting data. 

variance- this increases monotonically as flexibility increases, up to a point where there is overfitting. 


2.
Advantages (flexible): You have less bias and a better fit for non-linear models.

Disdvantages (flexible): Because we are estimating more parameters, it's more likey that we have overfitting from having too much noise. THis also means greater variance observed in the model. 


A more flexible approach would be better if we want to capture more complex patterns from a larger sample size. This is suitable when we care more about the prediction we can make with the data, although there may be more variance.

A less flexible is better when we have a less data and are more interested in trying to interpret or make sense of our results. However, we are more likely to have biased restuls.

3.a.
```{python}
# Import the libraries
import numpy as np
import os
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
```


3.b. There are 506 rows and 14 columns. The rows are the census tracts in Boston and the columns are the predictors.
Based on the text file, the variables reporesent these things specifically: 

```{python}
# Load the dataset
directory = r"C:\Users\clari\OneDrive\Documents\Machine Learning\ps1\Data-Boston\Boston"
boston_path = os.path.join(directory, "Boston.csv")
boston_df = pd.read_csv(boston_path)
print(boston_df.dtypes)
print(boston_df.shape)
```

CRIM     per capita crime rate by town
 ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
 INDUS    proportion of non-retail business acres per town
 CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
 NOX      nitric oxides concentration (parts per 10 million)
 RM       average number of rooms per dwelling
 AGE      proportion of owner-occupied units built prior to 1940
 DIS      weighted distances to five Boston employment centres
 RAD      index of accessibility to radial highways
 TAX      full-value property-tax rate per $10,000
 PTRATIO  pupil-teacher ratio by town
 B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
 LSTAT    % lower status of the population
 MEDV     Median value of owner-occupied homes in $1000's    

```{python}
# Lookup the missing values
print(boston_df.isna().sum())
```

3.c.

```{python}
pairwise = sns.pairplot(boston_df, vars = ['AGE', 'CRIM','MDEV', 'B', 'DIS'])
plt.show()
```


Age vs CRIM: More old buildings, more observations of crime and higher per capita crime rates by town

B vs DIS: Towns with a higher proportion of Black people are father from the Boston employment centers.

MDEV vs CRIM In homes not occuppied by owners, more observations of crime and higher per capita crime rates by town

DIS vs CRIM: There seems to be more and higher  per capita crime rates by town  when closer to the Boston employment centers.

DIS vs  AGE: It looks like a negative lniear relationship between the two. Towns with more pre 1940's buildings are  closer to the Boston  employment centers.


3.d. 
All the others that I chose seem to have a somewhat similar pattern. AGE and B, it is more like a positive correlation, meaning there are more observations and higher per capite crime rates in places with a higher proportion of older homes and Black population.  For MDEV and DIS, it looks like a negative correlation. However, none of these look like a clear linear relationship with crime. The data is even highly varied at some points.

3.e.
```{python}
#Box plot columns
box_values = ["CRIM", "TAX", "PTRATIO"]

fig, axs = plt.subplots(1, 3, figsize=(16, 9))

for i, col in enumerate(box_values):
    sns.boxplot(y=boston_df[col], ax=axs[i], color='purple')   
    axs[i].set_title(f"{col}")  
    axs[i].set_ylabel(col)  
    axs[i].set_xlabel("") 


plt.tight_layout()
plt.show()
```

*Reference* Lab  and  https://stackoverflow.com/questions/48176920/how-to-iteratively-plot-different-data-as-boxplots-in-seaborn-without-them-over

CRIM has the largest range. There is a small interquartiel range (most cities have low per capita crime rates) and a lot of outliers (values that fall outside of the min max whixkers). This may indicate some data measurement or encoding errors or something else that is  happening that must be investigated.

TAX has the narrowest range of the three. It seems that the broad IQR caputes most of the data, leaving no outliers.

Pupil-teacher ratios have a small range, the highest median among the three and have a large whixker range relative to the IQR(the min and max values are far from the middle values) and there are outliers. It is also more skewed to higher ratios

3.f. 
There are 35 census tracts that bound the Charles River. 
```{python}
chas_subset = boston_df[boston_df['CHAS'] == 1]
chas_count = chas_subset.shape[0]

print(f"There are {chas_count} tracts that bound the Charles River")
```

3.g.

```{python}
md_ptratio = boston_df["PTRATIO"].median()

print(f"The median PTRATIO is {md_ptratio}.")
```

3.h.
Get the min MDEV

```{python}
boston_df_sort = boston_df.sort_values("MDEV")

min_MDEV = boston_df_sort.head(5)

# Print the row
print(min_MDEV)
```

Tracts 398 and 405 have the minimum MDEV value of 5.

```{python}

min_MDEV_rows = boston_df.loc[[398, 405]]

# Getting the summary statistics for all predictors
summary_stats_MDEV = boston_df.describe().T[['min', 'max', 'mean']]

# Add the columns w the values from 398 and 405 to the summary
summary_stats_MDEV['Row_398'] = min_MDEV_rows.iloc[0]
summary_stats_MDEV['Row_405'] = min_MDEV_rows.iloc[1]


print(summary_stats_MDEV)
```

CRIM: Areas with this MDEV have per capita crime rates far above the min and mean. They are outlier values (see boxplot)


AGE:  Areas with this MDEV are outliers, with their AGE values being the maximum.

DIS:  Areas with this MDEV fall within the range of values, below the mean and above the minimum.

RAD:Areas with this MDEV are outliers, with their RAD values being the maximum.

CHAS: They are not bounded by the Charles river

TAX: Areas with this MDEV lie outside of the IQR (see boxplot), with their TAX values being closer to the maximum.

PTRATIO: Areas with this MDEV fall within the tange, bu are higher than the mean, closer to the max value.

LSTAT: Areas with this MDEV fall within the tange, bu are higher than the mean, closer to the max value.

3.i.
```{python}
# RM > 7
RM_7 = boston_df[boston_df["RM"] > 7]
RM_7_count = RM_7.shape[0]

# RM > 8
RM_8 = boston_df[boston_df["RM"] > 8]
RM_8_count = RM_8.shape[0]

print(f"There are {RM_7_count} rooms with an average of more than 7 rooms per dwelling")

print(f"There are {RM_8_count} rooms with an average of more than 8 rooms per dwelling")
```

Getting the summary stats
```{python}
# Summary stats for RM > 7
RM_8_summary = RM_8.agg(['mean', 'min', 'max']).T  

# Compute overall mean, min, and max for comparison
summary_stats_RM = boston_df.describe().T[['min', 'max', 'mean']]

# Combine the two summaries
comparison_summary_RM_7 = summary_stats_RM.join(RM_8_summary, lsuffix='_Overall', rsuffix='_RM>8')

# Display the comparison
print(comparison_summary_RM_7)


# Summary stats for RM > 8
RM_8_summary = RM_8.agg(['mean', 'min', 'max']).T  

# Compute overall mean, min, and max for comparison
summary_stats_RM = boston_df.describe().T[['min', 'max', 'mean']]

# Combine the two summaries
comparison_summary_RM_8 = summary_stats_RM.join(RM_8_summary, lsuffix='_Overall', rsuffix='_RM>8')

# Display the comparison
print(comparison_summary_RM_8)


```

On average, the tracts with greater than 8 rooms have a ver low CRIM, lower than the overall CRIM mean, while the  proportion of Black population is  higher than the mean, closer to the maximum overall value. A thing to note is that they do have a high MDEV as well, meaning that these rooms are likely rented out. 

4.a.

Y = 50 + 20(GPA) + 0.07(IQ) + 35(LVL) + 0.01(GPA * IQ) - 10 (GPA * LVL)
college: (LVL = 1)   35−10⋅GPA
highschool: (LVL = 0) 0
(35−10⋅GPA)−0=35−10⋅GPA
GPA = 
2, College students earn = 35 - 10 * 2 = 15K more

3, College students earn = 35 - 10 * 3 = 5k more

3.5, College students earn = 35 - 10 * 3.5 =  don't earn more

4, HS students = 35 - 10 * 4 = earn 5k more 

The correct answer is: iii. For a fixed value of IQ and GPA, high school graduates earn more, on average,
than college graduates provided that the GPA is high enough.


4.b. Predict the salary of a college graduate with IQ of 110 and a GPA of 4.0.
50 + 20(4) + 0.07(110) + 35(1) + 0.01(4 * 110) - 10 (4 * 1)
50+ 80 + 7.7 + 35 + 4.4 -40 = $137.1K

4.c.  False. We need look at the standard error of the coefficient, as well as the sigma squared (unexplained variation in Y).We learned that the magnitudes and indiv hypthesis tests aren't really good wys to asses the models.Sometimes, a small magnitutde might signify a big change (from GPA 3 to 4) vs IQ of 90 vs 130.Moreover, we want to look at it's relation to other predictors too.


5.a.
```{python}
# List of indevependnt variables
independent_var = boston_df.columns[1:]

# Function to fit a model and collect results
def simple_reg(x):
    reg = smf.ols(f"CRIM ~ {x}", data=boston_df).fit()
    return {
        "predictor": x,
        "coefficient": reg.params.iloc[1],
        "p-value": reg.pvalues.iloc[1],
        "adjusted R-squared (single)": reg.rsquared_adj
    }


# Apply the function to each predictor and create a DataFrame
results_simple_reg = pd.DataFrame([simple_reg(x) for x in independent_var])

print(results_simple_reg)
```

Sources: https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.rsquared_adj.html
https://stackoverflow.com/questions/41075098/how-to-get-the-p-value-in-a-variable-from-olsresults-in-python

PLotting 5 predictors
```{python}
# Loop
for x in independent_var[:5]:
    fig, ax = plt.subplots(figsize=(8, 12))
    
    # regression
    sns.regplot(x=x, y='CRIM', data=boston_df, ax=ax)
    
    ax.set_xlabel(x, fontsize=15)
    ax.set_ylabel("CRIM", fontsize=15)
    
    plt.show()
```

5.b.
```{python}
mult_reg = smf.ols(
    "CRIM ~ AGE + B + CHAS + DIS+ INDUS + NOX + RM + RAD + ZN + TAX + PTRATIO + LSTAT + MDEV", data=boston_df).fit()

print(mult_reg.summary())
```

The coefficients represent the estimated effect of a one unit change in each of the independent variables,
holding all other predictors constant. The intercept is the per capita crime rate when all the other predictors
are  0. We can reject the null hypothesis at the 5% significance level for the ff predictors which have a p-value
less than .05.: DIS, NOX, ZN, RAD, and MDEV for having low p-values.

5.c.
Create a plot displaying the univariate regression coefficients from Question (5a) on
the x-axis, and the multiple regression coefficients from Question (5b) on the y-axis.
```{python}
# Univariate regression coefficients
coefs_df = pd.DataFrame({
    "predictor": results_simple_reg["predictor"],
    "uni_coefs": results_simple_reg["coefficient"]
})

# Add multivariate coefficients to the df
coefs_df["multi_coefs"] = mult_reg.params.loc[independent_var].values

coefs_df = coefs_df.reset_index(drop=True)

# Plotting
fig, ax = plt.subplots(figsize=(8, 8))
sns.scatterplot(
    x="uni_coefs",
    y="multi_coefs",
    hue="predictor",
    palette="tab10", 
    data=coefs_df,
    ax=ax,
    s=100,
    edgecolor="black" 
)

# Setlabels
ax.set_title(
    "Coomparing Univariate vs Multivariate Coefficients", fontsize=16)
ax.set_xlabel("Univariate Regression Coefficients", fontsize=14)
ax.set_ylabel("Multivariate Regression Coefficients", fontsize=14)
ax.grid(True, linestyle="--", alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()
```

source:https://stackoverflow.com/questions/42767489/add-legend-to-seaborn-point-plot
*asked ChatGPT: Please help me refine with color palette an sizing.Helped me choose the best pallete and sizing to use for htis

Most of the data is clustered at the upperleft corner of the graphm wiith NOX being the one
outlier (a high univariate coef value, but low mutivariate coef value). It looks liek the coefficients do not match.
To observe the other data points more closely, we can redo the graph, without NOX so it will zoom in,

```{python}
fig, ax = plt.subplots(figsize=(8, 8))
sns.scatterplot(
    x="uni_coefs",
    y="multi_coefs",
    hue="predictor",
    palette="tab10", 
    data=coefs_df[coefs_df["predictor"]!="NOX"],
    ax=ax,
    s=100,
    edgecolor="black" 
)

# Setlabels
ax.set_title(
    "Coomparing Univariate vs Multivariate Coefficients", fontsize=16)
ax.set_xlabel("Univariate Regression Coefficients", fontsize=14)
ax.set_ylabel("Multivariate Regression Coefficients", fontsize=14)
ax.grid(True, linestyle="--", alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()
```

Now, we can see that the data is actually spread out--there are both positive and negative values.  Strangely, some values that are positive in the univariate regressio (PTRATIO and INDUS), are 
 negative in the multivariate, and vice versa (RM and ZN).

5.d.
```{python}
# Extracting adjusted R2 from earlier
linear_r2 = results_simple_reg[["predictor", "adjusted R-squared (single)"]].rename(
    columns={"adjusted R-squared (single)": "Adj R2 (Linear)"}
)

# Function for polynomial models and get adjusted R2
def fit_polynomial(data, predictor, response='CRIM'):
    # Fit polynomial model
    formula = f"{response} ~ {predictor} + I({predictor}**2) + I({predictor}**3)"
    model = smf.ols(formula, data=boston_df).fit()
    return model.rsquared_adj


# Fit polynomial models for each predictor
#empty list
polynomial_r2 = []
#loop and apply function
for predictor in linear_r2["predictor"]:
    adj_r2_poly = fit_polynomial(boston_df, predictor)
    polynomial_r2.append(
        {"predictor": predictor, "Adj R2 (Polynomial)": adj_r2_poly})

# Convert to DataFrame
polynomial_r2_df = pd.DataFrame(polynomial_r2)

# Merge  results into a table
comparison_df = linear_r2.merge(polynomial_r2_df, on="predictor")
comparison_df["Difference"] = (
   comparison_df["Adj R2 (Linear)"] - comparison_df["Adj R2 (Polynomial)"]
)

from tabulate import tabulate 
print(tabulate(comparison_df, headers="keys", tablefmt="grid"))

```

source: https://www.geo.fu-berlin.de/en/v/soga-py/Basics-of-statistics/Linear-Regression/Polynomial-Regression/Polynomial-Regression---An-example/index.html


table source: https://www.datacamp.com/tutorial/python-tabulate

For all non-indicator predictors, the adjusted R-squared is higher in the polynomial vs the simple regression, except for B. This means that the polynomial regression  explains more of the variation in the model, thus fits the data better. It also means that the additional coomplexity in the model did generally add value.
